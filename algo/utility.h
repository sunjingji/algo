#pragma once

#include <random>

// --------------------------------------------------------------------------------
// ❑ 欧几里得算法
// 用辗转相除的方法，求最大公约数。
// 注：书中用两端线段阐述的方法太有意思了。
//
// ------------------------------------------------------------------------------
// ❑ MurmurHash2
// 运行速度快、随机性好的哈希算法。
//
// ❑ Simhash
// 局部敏感性哈希算法，如果你对字符串做细微的修改，Simhash生成的散列值也只存在细微的差别。
// 需要检查两项内容的相似程度时，Simhash很有用。
//
// ------------------------------------------------------------------------------
// ❑ BloomFilmter
// 布隆过滤器的误判率，主要跟哈希函数的个数、位图的大小有关。
// 当我们往布隆过滤器中不停地加入数据之后，位图中不是true的位置就越来越少了，误判率就越来越高了。所以，对于无法事先知道要判重的数据个数的情况，我们需要支持自动扩容的功能。
// 应用：海量数据判重(网站uv统计，重复文件检测)
//
// ❑ HyperLogLog
// HyperLogLog是一种类似于布隆过滤器的概率型算法。
//
// ------------------------------------------------------------------------------
// ❑ 朴素贝叶斯算法
// 朴素贝叶斯模型的一个基本假设是条件独立，即假定w，w2，..., wn之间互相独立。这是一个较强的假设，正是这一假设，使朴素贝叶斯的学习与预测大为简化，且易于实现，其缺点是分类的准确率不一定高。
// 应用：垃圾信息分类
//
// --------------------------------------------------------------------------------
// ❑ 傅里叶变换
// 给它一杯冰沙，它能告诉你其中包含哪些成分。换言之，给定一首歌曲，傅里叶变换能够将其中的各种频率分离出来。
// 参考: Better Explained 网站
//
// ------------------------------------------------------------------------
// ❑ 向量空间
// 基于向量空间和欧几里得距离，可以考察相似度，进而实现简单的推荐系统，K近邻算法、聚类算法等。
//
// ------------------------------------------------------------------------
// ❑ KNN - K近邻算法
// 通过选择最近的N个节点，进行分类。
// KNN算法可以实现分类和回归，
//  - 分类就是编组；
//  - 回归就是预测结果，例如根据{天气指数，是不是节假日，有没有活动}预测面包店明天的销量；
// KNN实现需要考虑数据归一化(每个人的挑剔程度不同，对电影打的分数不同)，加权(意见领袖)等细节。
// 距离的计算方法在实际当中更常用的是余弦相似度。
//
// ------------------------------------------------------------------------
// ❑ 聚类
// 将相似的对象分为一组，通常使用欧几里得距离来衡量数据之间的相似度。
//
// k-means算法
// k-means算法是聚类算法中的一种，它可以根据事先给定的簇的数量进行聚类，算法步骤：
//  - 1)随机选择3个点作为簇的中心点。
//  - 2)计算各个数据分别和3个中心点中的哪一个点距离最近，将数据分到相应的簇中。
//  - 3)计算各个簇中数据的重心，然后将簇的中心点移动到这个位置。
//  - 4)重复第2、3步，直到中心点不再发生变化为止。
// 注:
//  - k-means算法中，随着操作的不断重复，中心点的位置必定会在某处收敛，这一点已经在数学层面上得到证明。
//  - 如果对簇的数量没有明确要求，那么我们可以事先对数据进行分析，推算出一个合适的数量，或者不断改变簇的数量来试验k-means算法。
//
//  - 即使簇的数量相同，只要随机设置的中心点最初的位置不同，聚类的结果也会产生变化。因此，我们可以通过改变随机设定的中心点位置来不断尝试k-means算法，再从中选择最合适的聚类结果。
//
// 层次聚类算法
// 除了k-means算法以外，聚类算法还有很多，其中“层次聚类算法”较为有名。与k-means算法不同，层次聚类算法不需要事先设定簇的数量。在层次聚类算法中，一开始每个数据都自成一类。也就是说，有n个数据就会形成n个簇。
// 然后重复执行“将距离最近的两个簇合并为一个”的操作n-1次。每执行1次，簇就会减少1个。执行n-1次后，所有数据就都被分到了一个簇中。
// 在这个过程中，每个阶段的簇的数量都不同，对应的聚类结果也不同。只要选择其中最为合理的1个结果就好。
// 合并簇的时候，为了找出“距离最近的两个簇”，需要先对簇之间的距离进行定义。根据定义方法不同，会有“最短距离法”“最长距离法”“中间距离法”等多种算法。
//
// --------------------------------------------------------------------------------
// ❑ 网页排名
// 网页排名算法使用连接数计算网页的权重，使用“随机游走模型”来解决链接结构为环状的问题。
//
void pagerank()
{
  int next[] = { 1,2,3,1 };
  int score[] = { 1,0,0,0 };
  int size = sizeof(next) / sizeof(int);
  int page = 0;
  double a = 0.15;
  std::minstd_rand0 randGenerator;
  randGenerator.seed((unsigned int)time(NULL));
  for (int i = 0; i < 1000; ++i) {
    int rand = randGenerator();
    if ((rand & 0xFFFF) < (a * 0xFFFF)) {
      int newpage = rand % size;
      while (newpage == page || newpage == next[page]) {
        newpage = randGenerator() % size;
      }
      page = newpage;
    }
    else {
      page = next[page];
    }
    ++score[page];
  }
  for (int i = 0; i < size; ++i) {
    printf("%d\n", score[i]);
  }
}